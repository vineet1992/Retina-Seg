
        #################################################
        ### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
        #################################################
        # file to edit: dev_nb/train_utils.ipynb


###Oversamples the minority class during training
import torch
import torch.nn as nn
import torch.nn.functional as F
from fastai.vision import *
from torch.utils.data.sampler import WeightedRandomSampler


class MultiLoss(nn.Module):
    def __init__(self):
        super(MultiLoss, self).__init__()
        self.pred_loss = nn.BCEWithLogitsLoss(reduction="mean")

    def forward(self, output,target_class):
        #if self.logits:
        #    BCE_loss = F.cross_entropy_with_logits(output, target, reduction='none')
        #else:
        class_loss = self.pred_loss(output, target_class)
        return class_loss
###TODO Change this to progress bar and fix errors

###This method outputs the logits for each class by predicting on the validation dataset
def get_logits(learn:Learner):
    learn.data.valid_dl.shuffle = False
    data_loader = learn.data.valid_dl
    data_loader.shuffle = False
    data_length = len(learn.data.valid_dl)
    output = torch.zeros(len(learn.data.valid_ds),2)
    allLabels = torch.zeros(len(learn.data.valid_ds))
    index = 0
    for batch, (images, labels) in enumerate(learn.data.valid_dl, 0):
        print(f'Step [{batch}/{data_length}], processed {len(labels)} images and size of output is {output.shape}')
        logits = learn.model.forward(*images)
        output[index:(index+learn.data.valid_dl.batch_size),:] = logits.data
        index = index + learn.data.valid_dl.batch_size
        allLabels[index:(index+learn.data.valid_dl.batch_size)] = labels.data
        del images
        del logits
        del labels
        torch.cuda.empty_cache()
    return(output,allLabels)

def tta_help(learn:Learner, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None,mdlVars:tuple = None, scale:float=1.35) -> Iterator[List[Tensor]]:
    "Computes the outputs for several augmented inputs for TTA"

    ###Grab the dataloader
    dl = learn.dl(ds_type)

    ###Grab the dataset for this dataloader
    ds = dl.dataset

    ###Grab the transformations already being done to this dataset (This will not work with a tabular/image dataset)
    #old = ds.tfms

    ###Do something with the loss function
    #activ = ifnone(activ, _loss_func2activ(learn.loss_func))


    ###
    #augm_tfm = [o for o in learn.data.train_ds.tfms if o.tfm not in
               #(crop_pad, flip_lr, dihedral, zoom)]

    #tfms = get_transforms(do_flip = False, max_rotate = 5.0, max_zoom = 1.1, max_lighting=0.3,max_warp = None)

    try:
        ##Create progress bar
        pbar = master_bar(range(8))
        for i in pbar:
            row = 1 if i&1 else 0
            col = 1 if i&2 else 0
            flip = i&4

            ###Treat these as key value arguments in function call
            #d = {'row_pct':row, 'col_pct':col, 'is_random':False}
            #tfm = [*augm_tfm, zoom(scale=scale, **d), crop_pad(**d)]
            #print(next(iter(learn.data.valid_dl)))

            ###Should we flip the image?
            #if flip: tfm.append(flip_lr(p=1.))

            ###Set the transforms equal to the ones mentioned
            #ds.tfms = tfm
            ###Run get predictions
            preds = []
            tfms = get_transforms(do_flip = False, max_rotate = 5.0, max_zoom = 1.1, max_lighting=0.3,max_warp = None)

            ###Replace get predictions to trace this PICK UP HERE TOMORROW
            it = iter(dl)
            count = 0
            for j in progress_bar(dl, parent=pbar):
            #for xb,yb in dl:
                xb,yb = next(it)

                ##xb[0][0] = 64 x num categorical tensor of categorical data, need to replace this with the category given from the probability in the model

                xb[1] = torch.stack([Image(x.to("cpu")).apply_tfms(tfms[0]).px for x in xb[1]]).cuda();
                if(mdlVars is not None):
                    start = count
                    end = count + learn.data.batch_size
                    if(end > xb[0][0].shape[0]):
                        end = xb[0][0].shape[0]
                    for k in mdlVars:
                        ###get model predictions
                        temp = mdlVars[k]
                        xb[0][0][:,k] = torch.tensor(np.where(np.array(temp[start:end,1])>=np.random.uniform(0,1,end-start),2,1)).cuda()
                out = learn.model(*xb)
                realPreds = F.softmax(out,dim=1)[:,1]
                preds.append(realPreds.data)
                del out
                del realPreds
                torch.cuda.empty_cache()
            yield torch.cat(preds)
    finally:
        print("out")
    ###Reset the transforms to the old ones
    #finally:





def TTA(learn:Learner, mdlVars:tuple=None, beta:float=0.4, scale:float=1.35, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None, with_loss:bool=False) -> Tensors:
    "Applies TTA to predict on `ds_type` dataset."
    if(mdlVars is None):
        preds,y = learn.get_preds(ds_type)
    else:
        dl = learn.dl(ds_type)
        it = iter(dl)
        count = 0
        preds = []
        y = []
        for j in progress_bar(dl):
            xb,yb = next(it)
            start = count
            end = count + learn.data.batch_size
            if(end > xb[0][0].shape[0]):
                end = xb[0][0].shape[0]
                ##xb[0][0] = 64 x num categorical tensor of categorical data, need to replace this with the category given from the probability in the model

            for k in mdlVars:
                    ###get model predictions
                temp = mdlVars[k]
                xb[0][0][:,k] = torch.tensor(np.where(np.array(temp[start:end,1])>=0.5,2,1)).cuda()
            out = learn.model(*xb)
            realPreds = F.softmax(out,dim=1)[:,1]
            preds.append(realPreds.data)
            del out
            del realPreds
            torch.cuda.empty_cache()
            y.append(yb)
    preds = torch.cat(preds)
    y = torch.cat(y)
    all_preds = list(tta_help(learn,ds_type=ds_type, activ=activ, scale=scale,mdlVars=mdlVars))
    avg_preds = torch.stack(all_preds).mean(0)
    if beta is None: return preds,avg_preds,y
    else:
        if(mdlVars is not None):
            final_preds = preds.to("cpu")*beta + avg_preds.to("cpu")*(1-beta)
        else:
            final_preds = preds[:,1]*beta + avg_preds.to("cpu")*(1-beta)
        if with_loss:
            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)
            return final_preds, y, loss
        return final_preds,y





class OverSamplingCallback(LearnerCallback):
    def __init__(self,learn:Learner):
        super().__init__(learn)
        self.labels = self.learn.data.train_dl.dataset.y.items
        _, counts = np.unique(self.labels,return_counts=True)
        self.weights = torch.DoubleTensor((1/counts)[self.labels])
        self.label_counts = np.bincount([self.learn.data.train_dl.dataset.y[i].data for i in range(len(self.learn.data.train_dl.dataset))])
        self.total_len_oversample = int(self.learn.data.c*np.max(self.label_counts))

    def on_train_begin(self, **kwargs):
        self.learn.data.train_dl.dl.batch_sampler = BatchSampler(WeightedRandomSampler(self.weights,self.total_len_oversample), self.learn.data.train_dl.batch_size,False)

from sklearn.metrics import roc_auc_score
from fastai.vision import *

def auroc_score(input,target):
    #if(target.shape[1]>1):
     #   target = target.cpu().numpy()[:,0]
    #else:
    target = target.cpu().numpy()
    input = input.cpu().numpy()[:,1]
    return roc_auc_score(target,input)

class AUROC(Callback):
    _order = -20 #Needs to run before the recorder

    def __init__(self, learn, **kwargs): self.learn = learn
    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])
    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []

    def on_batch_end(self, last_target, last_output, train, **kwargs):
        if not train:
            self.output.append(last_output)
            self.target.append(last_target)

    def on_epoch_end(self, last_metrics, **kwargs):
        if len(self.output) > 0:
            output = torch.cat(self.output)
            target = torch.cat(self.target)
            preds = F.softmax(output, dim=1)
            metric = auroc_score(preds, target)
            return add_metrics(last_metrics, [metric])

from torch import nn
import torch.nn.functional as F


class FocalLoss(nn.Module):
    def __init__(self, alpha=0.9, gamma=2, logits=False, reduction='elementwise_mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.logits = logits
        self.reduction = reduction

    def forward(self, output, target):
        if self.logits:
            BCE_loss = F.cross_entropy_with_logits(output, target, reduction='none')
        else:
            BCE_loss = F.cross_entropy(output, target, reduction='none')
        pt = torch.exp(-BCE_loss)
        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss

        if self.reduction is None:
            return F_loss
        else:
            return torch.mean(F_loss)


class WeightedFocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, logits=False, reduction='elementwise_mean'):
        super(WeightedFocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.logits = logits
        self.reduction = reduction

    def forward(self, output, target):
        ###Weight loss by second target variable (time to incidence)
        weights = target[:,1].float()
        target = target[:,0].long()

        if self.logits:
            BCE_loss = F.cross_entropy_with_logits(output, target, reduction='none')
        else:
            BCE_loss = F.cross_entropy(output, target, reduction='none')
        pt = torch.exp(-BCE_loss)
        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss * weights

        if self.reduction is None:
            return F_loss
        else:
            return torch.mean(F_loss)
        #F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss * torch.stack([weights,weights],1).float()

###Helper functions to get output from predictions on the tuning set
def roc_curve(preds,y,flip=False):

    ###Extract probabilities only for class 1 (I believe this is Male but need to check)
    if(flip):
        if(len(preds.shape)!=1):
            preds = np.array(preds[:,0])
        y = np.array(1-y)
    else:
        if(len(preds.shape)!=1):
            preds = np.array(preds[:,1])
        y = np.array(y)


    from sklearn.metrics import roc_curve, auc
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    fpr, tpr, _ = roc_curve(y, preds)
    roc_auc = auc(fpr, tpr)
    return fpr,tpr,roc_auc

def plot_roc(fpr,tpr,roc_auc,title):
    plt.figure()
    lw = 2
    plt.plot(fpr, tpr, color='darkorange',
             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

###The idea is to randomly sample the time from 0 to follow-up time for each example, adjust the label
## if the sampled time is before when the event actually occurred
import random as rd

class TabCensDataset(Dataset):
    """A Dataset of combined tabular data, image names, and targets."""
    ###Assume the first continuous variable is the time-to-event
    def __init__(self, x_cont, x_cat,y,max_time,train=True):
        ##If this isn't the training set, then get predictions for the max_time length of follow-up
        if(train):
            self.tte = x_cont[:,0]
            self.x_cont = x_cont[:,1:x_cont.size()[1]]
        else:
            follow_time = torch.tensor(max_time)
            follow_time = follow_time.repeat(x_cont.size()[0],1)
            self.x_cont = torch.cat([follow_time.type(FloatTensor),x_cont[:,1:x_cont.size()[1]]],1)


        self.x_cat = x_cat
        self.y = y
        self.is_empty = False
        self.train=train
        self.max_time = max_time
        ###Time-to-event so assume 2
        self.c = 2

    def __len__(self): return len(self.y)

    def __getitem__(self, i):
        if(not self.train):
            return (self.x_cont[i],self.x_cat[i]),self.y[i]
        else:

            ###randomly sample the follow-up time
            y = self.y[i]
            ###event occurred so sample from 0 to max follow up
            if(y==1):
                follow_up = torch.tensor(rd.uniform(0,self.max_time))
                ###Adjust y accordingly to the sampled follow-up time
                if(follow_up < self.tte[i]):
                    y = torch.tensor(0)
            else:
                follow_up = rd.uniform(0,self.tte[i])


            return(torch.cat([follow_up.unsqueeze(-1),self.x_cont[i]]),self.x_cat[i]),y

class TabCensModel(nn.Module):
    """A Tabular NN model for censored data"""

    ###n_cont = number of continuous variables
    ###cats = list of number of categories of each discrete variable
    ###linear layers after embedding
    ###ps = probability of something? fastai
    ###emb_drop = probability of
    def __init__(self, n_cont,cats,layers = [32,32],ps = [0.25],emb_drop=0.05,output_dim=2):
        super().__init__()
        self.embeds = []
        self.emb_drop = nn.Dropout(emb_drop)
        self.bn_cont = nn.BatchNorm1d(n_cont)
        self.n_cont = n_cont
        self.cats = cats
        self.output_dim = output_dim
        out_cats = [round(1.6*i**0.56) for i in cats]
        mapping = zip(cats,out_cats)
        #total_cats = 0
        #for i in cats:
            #curr_len = i
            #out_len = round(1.6 *i**0.56)
            #self.embeds.append(nn.Embedding(i,out_len))
            #total_cats = total_cats + out_len

        self.embeds = nn.ModuleList([embedding(ni, nf) for ni,nf in mapping])
        self.total_cats = sum(e.embedding_dim for e in self.embeds)
        self.input_features = n_cont + self.total_cats


        self.layers = nn.Sequential()


        prev_layer =self.input_features
        for i in range(0,len(layers)):
            self.layers.add_module('Dense' + str(i),nn.Linear(prev_layer,layers[i]))
            self.layers.add_module('ReLU' + str(i),nn.ReLU(layers[i]))
            prev_layer = layers[i]
        ###Add output layer
        self.layers.add_module('Output',nn.Linear(prev_layer,self.output_dim))

    def forward(self, x_cont,x_cat):
        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]
        x = torch.cat(x, 1)
        x = self.emb_drop(x)

        x_cont = self.bn_cont(x_cont)

        ###Put categorical and continuous features together and run
        x = torch.cat([x_cont, x], dim=1)
        return self.layers(x)





class TabConvCensData(Dataset):
    """A Dataset of combined tabular data, image names, and targets."""
    def __init__(self, x_tab, x_img, train=True):
        if(train):
            self.tfms = get_transforms(do_flip = False, max_rotate = 5.0, max_zoom = 1.1, max_lighting=0.3,max_warp = None)
        else:
            self.tfms = None
        self.x_tab = x_tab
        self.x_img = x_img
        self.is_empty = False
        self.set = False
        self.train=train
        self.c = 2

    def __len__(self): return len(self.x_tab)

    def __getitem__(self, i):
        x,y = self.x_tab[i]
        x_cont = x[0]
        x_cat = x[1]
        if(not self.train):
            return (x_cont,x_cat,self.x_img[i].px),y
        else:
            ###Transform the image
            if(self.tfms is not None):
                tmp = self.x_img[i].apply_tfms(self.tfms[0]).px
                return (x_cont,x_cat,tmp),y



class TabConvCensModel(nn.Module):
    """A combined neural network using the convnet and tabular model"""
    def __init__(self, tab_model, img_model, layers, drops):
        super().__init__()
        self.tab_model = tab_model
        self.img_model = img_model
        lst_layers = []

        activs = [nn.ReLU(inplace=True),] * (len(layers) - 2) + [None]

        for n_in, n_out, p, actn in zip(layers[:-1], layers[1:], drops, activs):
            lst_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn)

        self.layers = nn.Sequential(*lst_layers)

    def forward(self, *x):
        x_tab = self.tab_model(x[0],x[1])
        x_img = self.img_model(x[2])

        x = torch.cat([x_tab, x_img], dim=1)
        return self.layers(x)